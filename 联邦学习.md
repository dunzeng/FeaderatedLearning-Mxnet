# 隐私保护的分布式机器学习系统

## 网络通信管理类Server：

监听端口

处理Client端交互信息，并将控制信息交付至数据维护类

### 数据维护类Server_data_handler：

维护Server端后台模型

负责数据操作

## 网络通信管理类Client：

维护网络通信

与参数服务器交流，发送控制信息，与后台模型交流

### 数据维护类Client_data_handler：

持有本地数据集

在本地数据集上训练模型

### Algorithm包：

------

提供基础扩展算法，包括神经网络模型以及Fed训练算法。

## 系统架构思想：

联邦学习服务器维护一个统一模型，参与者当想将自身拥有的数据加入学习过程，应与服务器产生联系，并沟通交互细节。连接建立成功后，服务器向参与者分享当前的模型，参与者在本地进行模型训练，并将梯度回传给服务器。~~服务器自行决定是否进行梯度更新。~~

拥有数据的参与者获得与服务器分享模型的机会。

~~采用有限自动机构建服务器与参与者之间沟通的状态定义。~~

~~New Idea： 去中心化架构，参与者构成信息流环，信息在参与者中限制拓扑流通？~~

## 进展日志

12.15 完善参数管理数据结构类 parameters； 

​			实现服务端通信类SokectServer：定义服务器与参与者的交互协议：

​			1、前四个字节作为控制信息： 1001请求参与，1002请求模型参数，1003确认模型类型，1004回馈梯度

​			参数服务器架构问题：

​					参数服务器包括：模型管理数据结构，网络通信数据结构

12.16 修改服务端架构，将网络管理类作为基础类

​			ndarry在MXnet中对Dense权值矩阵直接赋值[:]

​			编写参与者端的网络模块

​			服务端采用TCP二进制文件传输方式发送模型

12.17 初步完成参与者类Participant，待测试梯度更新方法，待确认服务器端多线程调度方算法

​			朴素联邦学习方法：单线程阻塞式，同一时间只允许单个参与者获取当前模型

​			初步采用训练集整体梯度作为局部梯度上传服务器（测试）

​			参与者梯度回传方法，pickle序列化字典，socket回传字典

​			梯度回传状态确认

​			TODO: 测试梯度获取方法，实现梯度端到端传递方法，实现globel model梯度更新

12.18 测试梯度计算方法，完善梯度发送的网络方法，完善朴素算法网络交互模块

​		   完成服务端parameters类中维护模型和梯度更新方法

​			TODO: 测试

12.22 添加测试方法

​			朴素方法单服务器单参与者测试成功

​			TODO: 多数据集学习测试，多机网络，提示信息优化。

12.25 participant类代码优化 优化代码结构 添加进度条

​			朴素方法多数据集测试： 0.92 0.93 0.89 0.83 0.71  失败  

​					原因：算法错误，服务端发送模型未更新。

​			TODO: 算法流程检查，多机训练测试

12.26  多轮训练结果失败，算法流程check，参与者端的模型接收函数出错

​			单机多轮训练结果成功, round5 validation rate: 0.93

​			version1.1 workable

12.30 TODO:《Privacy-Preserving Deep Learning》论文算法加入  version 2.0

​			需求分析，算法架构完成

1.2 着手添加SSGD算法模块，完成Selective Gradient Update部分函数

​		TODO：架构分析，模块优化

1.3 完成SSGD函数

​		TODO： 算法流程分析，单元测试

1.5 单元测试，算法流程检查与分析，代码review

--新年快乐--

1.27 代码复习，架构分析

模型自定义算法，服务器部署模型，客户端询问服务器模型结构，服务器动态生成模型结构生成代码，传回客户端。

2.2  代码重测 朴素算法无BUG

​		SSGD算法测试

2.3 架构思想添加：服务器核心架构，服务器部署，参与者端部署由服务器自动化部署，算法参数自定义，模型结构自定义。

​	代码架构合理化。

​	mxnet更新，朴素算法出现bug

2.5 修复朴素算法bug

​		TODO 测试SSGD参数选择模块，测试SSGD算法

​					实现动态自定义模型结构

2.6 修复SSGD流程算法，编写代码

2.7 成功跑通SSGD流程算法，但计算效率低，准确率不提升

​		TODO：check算法流程，修改代码结构，测试准确率参数

2.16 添加json文件自定义配置系统参数；

​		~~研究mxnet框架下，自定义神经网络模型架构的方法及实现；（同jison文件格式自定义，读取json内容）~~

​		系统架构更新，SocktServer类负责Server与Client的通信，param负责模型内部数据处理，通过初始化为不同的param产生不同的神经网络架构 NN,CNN,RNN等，相应的参数更新和发送也发生改变。

2.17 自定义网络架构中，将param作为负责模型内部处理，param类与自定义模型关系密切，将 param类改为可由用户继承重写，传入SocktServer类，作为成员，以此实现用户自定义模型。

​		将参与者类再抽象分为两个独立工作的类，类比服务器端架构，一个类作为维持网络通信，另一个类负责后台数据处理。

2.18 ~~想法：实现UI，将用户自定义网络采用使用带ui程序定义生成json格式文件。~~

​					梯度传递为列表传递，顺序对应遍历神经网络层对应带参数的层。

2.19 重构代码，提高可拓展性，和用户自定义

​		重构架构：Server和Client端只集成朴素联邦学习算法，其他变形算法另外编写工具类应用

2.20 添加SSGD算法工具类：SSGD_Server,SSGD_Client。提供SSGD算法中必要的方法。

​		想法: 参数选择算法：将（weight，引用）按照weight排序，直接将低值引用指向的位置赋0，复杂度O(NlogN)

​		Todo：~~模型遍历~~，加密算法，稀疏矩阵分解，~~mxnet学习~~，横向/纵向/迁移联邦学习

2.21 想法：多Clients情况下，Server指定不同的Client对不同的参数进训练并进行梯度更新。

​					异步联邦学习

​		架构更新：添加mxnet中自定义网络类

2.22-2.23 学习循环神经网络，学习Mxnet框架实现细节

​				 代码更新：网络参数遍历方法更新。

2.24 尝试编写RNNModel类，包含常用RNN模型：rnn, LSTM, GRU

​		进一步抽象联邦学习系统，优化代码，提高系统通用性：系统仅提供网络通信协议，参数交换，梯度交换等功能。负责Server与Client的信息交流，与拓扑逻辑维护。

2.25 RNN模型训练fail

​		~~想法：假设宏观数据符合同一概率分布，局部数据非独立同分布~~

​					~~可考虑由Client端给出数据集的损失函数值，再由服务端求梯度，服务端回传梯度~~

2.26 暂停算法类的设计，偏向联邦系统功能架构设计：面向研究者代码快速实现

​		sleepy

2.27 Rest

2.28 更新代码

​		添加CNN模块：包括常规CNN模型LeNet、AlexNet、VGG

​		更新Algorithm包中 SSGD代码 更新nn.Sequential类遍历方法

2.29 考虑添加：UDP协议传输控制码信息、ssh加密梯度和模型传输

​							梯度压缩算法、模型广播压缩、本地计算压缩

​		学习论文 

> *Advances and Open Problems in Federated Learning*
>
> *Differentially Private Federated Learning: A Client Level Perspective* 
>
> Communication-Efficient Learning of Deep Networks from Decentralized Data

 3.1 学习论文

> Communication-Efficient Learning of Deep Networks from Decentralized Data

​	Algorithm :

​		*Federated Averaging*:

​		思想：1. 定义f(w)等于损失函数的算术平均值，最小化平均后的损失函数f(w)

​					2. 从n个Clients选出K个clients，每个client的本地数据集为Pk

​						对于每个Pk，定义fk(w)等于在该划分数据集下损失函数的算术平均

​						重写f(w)为K个fraction下的数据集关于算术平均后损失函数fk(w)的和

​					（数学描述见paper p3左上）

​		理解：client训练，更新模型参数后，K个client的weight在服务端的算术平均作为global_model

​	~~IDEA: 关于模型在non-IID数据下的训练问题。我有一个假设，宏观大数据符合某一分布规律，但是在client端由于用户数据差异，会出现non-IID数据的情况，增加了联邦学习模型的难度。我想如果Server端把模型参数发送至Clients，然后Clients进行计算，只将损失函数结果发送回Server端，（这里比如可以对收到的所有损失函数值进行随机采样）而由Server端进行梯度计算，用于迭代模型。因为在回传的损失函数结果信息中，藏有各个client的数据分布情况，所以当损失函数在Server端合并后，就会符合假设中的同一分布规律，这时Server端进行学习，就可以学到这个规律，从而提高泛化性能。~~

3.4 添加Federated Averaging算法，更新client端和server端信息交流函数

​	 NewIdea：联邦增强树算法

3.5 复习Adaboost，思考新IDEA的可行性

3.9 联邦投票树基本思想的数学描述：

​			
$$
对于由Client_i本地数据所训练出的K分类器f_i(x;w_i)\\有f_i(x;w_i)=y \in R^{1 \times K};\\
定义投票系数T_i \in R^{1 \times k},其含义为分类器i输出f_i(x;w)对下标对应分类正确性的投票\\
定义Server端训练算法:\\
输入弱分类列表f(x;w)\\
Server端通过计算得出投票系数列表T\\
输出最终分类器 G(x) = sign(\sum{T_i\ast f_i(x;w_i)}),其中\ast为Hadamard乘积
$$
​		针对问题：面向横向联邦学习问题，提高联邦学习模型在Non-IID数据的情况下准确性。

​		基本思想：由于各Client之间的数据不符合同一概率分布，因此用不同数据训练出的模型受本地训练数据集的影响较大，对于陌生数据不敏感（譬如手写数字识别，由缺少数字9的数据集训练出的模型，对识别数字9可能会出错，因为从未见过数字9）。Server可以对Client上传的模型进行整合处理，即用Server端存在的数据对Client端模型进行修正（上一例子中即降低该分类器对预测输出9的权值，对Client端模型对不同类的误分类率进行计算，通过误分类率定义弱分类器对某一分类的预测的可靠性）。最终通过线性组合，找出各个弱分类器投票所获得权值最大的类作为预测类输出。

​		挑战：需要设计合理的算法求投票系数T
$$
即{\underset {T} {\operatorname {min}}}\sum{L(y,\sum T_i\ast f_i(x;w))}
$$
​		弊端： Server端需要有比较符合真实情景的数据集用于计算T；由于是由多模型线性组合的分类器，做一次预测的计算量为单模型计算量的倍数；

3.10 开始实验研究FedVoteTree算法有效性

​		思考联邦投票树的训练算法 

3.11 测试代码

​		 学习提升树算法

----看paper----

3.21 考虑添加Deep Gradient Compression算法降低梯度通信带宽

​		 重写Client端训练算法、求梯度方法 gradient = grad*learning_rate/batch_size

3.22 完善Client端梯度回传方法

​		TODO：设计投票树算法实验，架构功能接口通用化，系统参数初始化，多机模拟训练实验

3.25  基本架构work 多client测试失败

​		  单元测试训练成功， 联邦学习测试失败，可能原因 梯度传输/收集出错；Server端交流与模型更新协同出错；拓扑关系混乱；

​		 TODO：BUG修改、控制台输出信息优化、log类

3.26 replace训练模式下模型可行 但是; 

​		gradient训练模式下出错 可能原因梯度传输出错；

​		working：添加log类用于bug检查

3.27 log文件测试 梯度传递无信息损失

​		log文件测试 梯度更新后模型不同步

​		寻找bug失败 再接再厉

3.28 Bug测试顺序： 

- [x] ​				模型传输测试

- [x] ​				梯度传输测试

- [x] ​				模型更新测试  Server端进行自动梯度更新时出现差错  原因不明

3.29 Debug完成，gradient模式下训练成功，这个bug困扰了我小半个周，写了很多测试程序，至今不知bug原因（通过测试程序缩小bug范围，重写关键函数解决），解决问题得耐心。

​		 TODO:   修复为了Debug写的乱七八糟的源码结构。

​						测试SelectiveSGD算法，实现DGC和FedAvg算法。

3.30 看文档，修复源码

3.31 思考联邦学习扩展算法的添加与集成，复习paper并着手测试FedAvg算法。

4.1 着手毕业论文的写作，准备将Server端采取多线程模式，提高服务器吞吐率

4.8 毕业论文理论部分第一版基本完成，开始着手实验内容与数据部分。

​	   Server端多线程模式已完成。

​	   接下来着手Federated Averaging算法实验部分。

4.9 FedAvg算法复现实验， 系统内存优化。

4.10 FedSGD实验完成，待完成该部分论文写作。

4.11 LaTex算法伪代码排版

4.12 完成第五章和第六章开头论文的编写，开始着手实验，数据记录，代码框架调整等工作。

4.13 Fed Banlance算法： 通信与计算量之间的trade-off方法（待验证，似乎是理论可行）。

4.13 论文实验，插图排版。

​		 实验设计：测试FedAvg算法中，参数C对模型收敛的影响。

​							C = 0，0.1，0.2，0.5，1

​							E = 10, 100, 无穷

communicate round

| E\C  | 0    | 0.1  | 0.2  | 0.5  | 1    |
| ---- | ---- | ---- | ---- | ---- | ---- |
| 10   |      |      |      |      |      |
| 100  |      |      |      |      |      |
| 无穷 |      |      |      |      |      |

4.16 FedAvg不work; Bug作祟。  

​		 用try except捕捉错误时一定要raise

4.17 FedAvg算法训练时存在BUG，Debug中。

​		修改源码结构

​	     暂时搁置FedAvg实验，着手中心化训练和FedSgd算法的比较。

​	learning_rate  batch_size 

​																				epoch														cummunicate round E=5

| mlp accuracy>=97%           | 200  | 100  | 50   | 10   | 200  | 100  | 50   | 10   |
| --------------------------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 0.01                        | 84   | 41   | 23   | 6    | 1666 | 860  | 471  | 151  |
| 0.02                        | 43   | 21   | 11   | 3    | 860  | 471  | 264  | 115  |
| 0.04                        | 21   | 11   | 6    | 3    | 471  | 288  | 204  | 107  |
| **LeNet-5 accuracy>=98.8%** |      |      |      |      |      |      |      |      |
| 0.01                        | 132  | 66   | 29   | 11   | 2555 | 1830 | 730  | 271  |
| 0.02                        | 54   | 27   | 18   | 4    | 1430 | 710  | 533  | 235  |
| 0.04                        | 34   | 13   | 11   | 6    | 910  | 724  | 249  | 236  |



4.22 计算量对比实验完成，开始尝试FederatedAvg模拟算法。

| CNN, E=5 | 10   | 50   | 100  | communicate round |
| -------- | ---- | ---- | ---- | ----------------- |
| 0.1      |      |      |      |                   |
| 0.2      |      |      |      |                   |
| 0.5      |      |      |      |                   |
| 1.0      |      |      |      |                   |



4.23 FedAvg模拟实验暂时无效

